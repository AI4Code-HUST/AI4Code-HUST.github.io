<!DOCTYPE html>
<html>
	<head>
		<script async src="https://rum.cronitor.io/script.js"></script>
	<script>
		window.cronitor = window.cronitor || function() { (window.cronitor.q = window.cronitor.q || []).push(arguments); };
		cronitor('config', { clientKey: 'd7b31d7abbb37752a51401f70577586f' });
	</script>
		<script src="https://kit.fontawesome.com/1a146c3d53.js" crossorigin="anonymous">
            
        </script>

		<meta charset="UTF-8" />

		<title>Thanh Le-Cong @ The University of Melbourne</title>
		
		<meta name="keywords" content="Thanh Le-Cong, Cong Thanh Le, Thanh Le-Cong SMU, Thanh Le-Cong University of Melbourne" />
	 	<meta name="description" content="Homepage, Thanh Le-Cong, The University of Melbourne, Melbourne, Australia" />
        <link rel="stylesheet" href="css/style.css" />
        <link rel="stylesheet" href="css/fonts.css" />
        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Nunito:ital,wght@0,400;0,500;0,600;0,700;1,400;1,500;1,600;1,700&family=Quicksand:wght@400;500;600;700&display=swap" rel="stylesheet">
        <link href="fontawesome-free-6.5.1-web/css/fontawesome.css" rel="stylesheet">
        <link href="fontawesome-free-6.5.1-web/css/brands.css" rel="stylesheet">
        <link href="fontawesome-free-6.5.1-web/css/solid.css" rel="stylesheet">
    </head>
	
	<body>
        <nav>
        <ul class="menu">
          
            <li><a href="./index.html">Home</a></li>
            <li><a href="./publications.html">Publications</a></li>
            <li><a href="./experiences.html">Experiences</a></li>
            <li><a href="./services.html">Services</a></li>
            <li><a href="./travelmap.html">TravelMap</a></li>

        </ul>
        <hr/>
        </nav>

    
    <h1 id="overview">Reliablity of Large Language Models</h1>
    <p>
        <b>Motivation:</b> Large Language Models (LLMs) have demonstrated remarkable performance across diverse tasks, including software engineering tasks. Through training on vast amounts of data, LLMs exhibit an unprecedented capacity on understanding and generating human-like responses, rendering them highly suitable for various applications such as code summarization or code generation. Unfortunately, while LLMs have shown great promise, the reliability of ChatGPT-generated responses are still questionable. 
        </p>
        
        <p>
        <b>Approach:</b> This theme aim to explore unknown issues and gain empirical insights regarding the reliability of LLM-generated responses. Drawing insights from this investigation, I aim to propose effective solutions that can address identified issues. Towards this goal, my colleagues and I have conducted a comprehensive array of empirical studies to explore explore unknown issues in various SE-related tasks including:
        <li>
        <b>Code Generation:</b> LLMs are widely-used for code generation with various systems including ChatGPT, Codex and GitHub Copilot. However, the reliablity of generated code is still questionable. To investigate unknown issues, we systematically study the quality of 4,066 LLM-generated code implemented in two popular programming languages, i.e., Java and Python, for 2,033 programming tasks [<a href="https://arxiv.org/abs/2307.12596"> Submitted to TOSEM</a>]. Our study unveils various issues in LLM-generated code including solution inaccuracies and maintainability issues. We also demonstrated LLM's capabilities on self-mitigating the issues.
        </li>
        
        <li>
        <b>Technical Q&A:</b>  ChatGPT, a well-known LLM, is banned by Stack Overflow after only 6 days from its release. The main reason provided by the official Stack Overflow is that the answers generated by ChatGPT are of low quality. To verify this, we conduct a comparative evaluation of human-written and ChatGPT-generated answers and suggest that human-written and
        ChatGPT-generated answers are semantically similar, however, human-written answers outperform ChatGPT-generated ones consistently across multiple aspects [<a href="./pdf/ASE_LLMQA.pdf"> ASE'23</a>].
        </li>
        </p>

    <h1 id="pubs">Related Publications</h1>
    <h3>[TOSEM] Refining ChatGPT-Generated Code: Characterizing and Mitigating Code Quality Issues?</h3>
    <ul>
    <li><strong>Authors:</strong> Yue Liu, <strong style="color: black;">Thanh Le-Cong</strong>, Ratnadira Widyasari, Chakkrit Tantithamthavorn, Li Li, Bach Le, David Lo</li>
    <li><strong>Venue:</strong> ACM Transactions on Software Engineering and Methodology</li>
    <li><strong>One-line Abstract:</strong> An empirical study on code quality issues in ChatGPT-generated code.</li>
    <li><strong>Links:</strong>
        <a href="./pdf/TOSEM_LLMQuality.pdf"><img src="https://img.shields.io/badge/PDF-b31b1b.svg"></a> <a href="https://github.com/thanhlecongg/thanhlecongg.github.io/blob/simple_homepage/overview/ChatGPT_CodeQuality/overview.md"><img src="https://img.shields.io/badge/Overview-orange"></a>
    </li>
    </ul>

    <h3>[ASE'23] Are We Ready to Embrace Generative AI for Software Q&A?</h3>
    <ul>
    <li><i class="fa fa-users"></i> <strong>Authors:</strong> Bowen Xu, Thanh-Dat Nguyen, <strong style="color: black;">Thanh Le-Cong</strong>, Thong Hoang, Jiakun Liu, Kisub Kim, Chen Gong, Changan Niu, Chenyu Wang, Bach Le, David Lo</li>
    <li><i class="fa fa-book"></i> <strong>Venue:</strong> IEEE/ACM 35th International Conference on Automated Software Engineering (ASE) 2023, New Ideas and Emerging Results (NIER) Track [<strong>Acceptance Rate:</strong> 36%]</li>
    <li><i class="fa fa-file"></i> <strong>One-line Abstract:</strong> A comparative evaluation between ChatGPT-generated and Human-generated answers for Software Q&A.</li>
    <li><i class="fa fa-link"></i> <strong>Links:</strong>
        <a href="https://www.computer.org/csdl/proceedings-article/ase/2023/299600b713/1SBGkVjZUZO"><img src="https://img.shields.io/badge/DOI-green"></a> <a href="./pdf/ASE_LLMQA.pdf"><img src="https://img.shields.io/badge/PDF-b31b1b.svg"></a>
    </li>
    </ul>

    <footer>
        <script src="js/math-code.js"></script>
        <script async src="//cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
        <script async src="js/center-img.js"></script>
        <hr>&copy; <a href="https://thanhlecongg.github.io">Thanh Le-Cong</a> 2023 | <a href="https://twitter.com/ThanhLeCong2705"><i class="fa-brands fa-twitter" style="color: #00bfff;"></i></a>
        <a href="https://www.linkedin.com/in/thanhlecong/"><i class="fa-brands fa-linkedin" style="color: #0457e7;"></i></a>
        <a href="https://github.com/thanhlecongg"> <i class="fa-brands fa-github"></i></a>
        <a href="https://www.facebook.com/thanh.toanlamson"><i class="fa-brands fa-facebook" style="color: #005af5;"></i></a>
      </footer>
    
    </body>
</html>



